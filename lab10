import os
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow import keras
from utils.models import create_vae_model
from utils.losses import reconstruction_loss
from utils.callbacks import SaveDecoderOutput, SaveDecoderModel
os.environ["CUDA_VISIBLE_DEVICES"] = "0"


def parse_fn(dataset, input_size=(28, 28)):
    x = tf.cast(dataset['image'], tf.float32)
    x = tf.image.resize(x, input_size)
    x = x / 255.
    return x, x


dataset = 'mnist'     # 'cifar10', 'fashion_mnist', 'mnist'
log_dirs = 'logs_vae'
batch_size = 16
latent_dim = 2
input_shape = (28, 28, 1)

# Load datasets
train_data = tfds.load(dataset, split=tfds.Split.TRAIN)
test_data = tfds.load(dataset, split=tfds.Split.TEST)

# Setting datasets
AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式
train_data = train_data.shuffle(1000)
train_data = train_data.map(parse_fn, num_parallel_calls=AUTOTUNE)
train_data = train_data.batch(batch_size)
train_data = train_data.prefetch(buffer_size=AUTOTUNE)
test_data = test_data.map(parse_fn, num_parallel_calls=AUTOTUNE)
test_data = test_data.batch(batch_size)
test_data = test_data.prefetch(buffer_size=AUTOTUNE)

# Callbacks function
model_dir = log_dirs + '/models'
os.makedirs(model_dir, exist_ok=True)
model_tb = keras.callbacks.TensorBoard(log_dir=log_dirs)
model_sdw = SaveDecoderModel(model_dir + '/best_model.h5', monitor='val_loss')
model_testd = SaveDecoderOutput(28, log_dir=log_dirs)

# create vae model
vae_model = create_vae_model(input_shape, latent_dim)

# training
optimizer = tf.keras.optimizers.RMSprop()
vae_model.compile(optimizer, loss=reconstruction_loss)
vae_model.fit(train_data, epochs=20, validation_data=test_data, callbacks=[model_tb, model_sdw, model_testd])



import os
import numpy as np
import tensorflow as tf


class SaveDecoderOutput(tf.keras.callbacks.Callback):
    def __init__(self, image_size, log_dir):
        super(SaveDecoderOutput, self).__init__()
        self.size = image_size
        self.log_dir = log_dir
        n = 15
        self.save_images = np.zeros((image_size * n, image_size * n, 1))
        # linearly spaced coordinates corresponding to the 2D plot of digit classes in the latent space
        self.grid_x = np.linspace(-1.5, 1.5, n)
        self.grid_y = np.linspace(-1.5, 1.5, n)

    def on_train_begin(self, logs=None):
        path = os.path.join(self.log_dir, 'images')
        self.writer = tf.summary.create_file_writer(path)

    def on_epoch_end(self, epoch, logs=None):
        for i, yi in enumerate(self.grid_x):
            for j, xi in enumerate(self.grid_y):
                z_sample = np.array([[xi, yi]])
                img = self.model.get_layer('decoder')(z_sample)
                self.save_images[i * self.size: (i + 1) * self.size, j * self.size: (j + 1) * self.size] = img.numpy()[0]
        with self.writer.as_default():
            tf.summary.image("Decoder output", [self.save_images], step=epoch)


class SaveDecoderModel(tf.keras.callbacks.Callback):
    def __init__(self, weights_file, monitor='loss', save_weights_only=False):
        super(SaveDecoderModel, self).__init__()
        self.weights_file = weights_file
        self.best = np.Inf
        self.monitor = monitor
        self.save_weights_only = save_weights_only

    def on_epoch_end(self, epoch, logs=None):
        loss = logs.get(self.monitor)
        if loss < self.best:
            if self.save_weights_only:
                self.model.get_layer('decoder').save_weights(self.weights_file)
            else:
                self.model.get_layer('decoder').save(self.weights_file)
            self.best = loss


import tensorflow as tf


def mse_loss(y_true, y_pred):
    return tf.reduce_mean(tf.reduce_sum(tf.math.squared_difference(y_true, y_pred), axis=[1, 2, 3]))


def reconstruction_loss(y_true, y_pred):
    bce = y_true * tf.math.log(y_pred + 1e-07) + (1 - y_true) * tf.math.log(1 - y_pred + 1e-07)
    return tf.reduce_mean(tf.reduce_sum(-bce, axis=[1, 2, 3]))


import numpy as np
import tensorflow as tf
from tensorflow import keras


class Sampling(keras.layers.Layer):
    """Uses (z_mean, z_var) to sample z, the vector encoding a digit."""
    def call(self, inputs):
        z_mean, z_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape=(batch, dim))
        return z_mean + tf.exp(z_var) * epsilon


def create_vae_model(input_shape, latent_dim):
    # Define encoder model.
    img_inputs = keras.Input(input_shape)
    x = keras.layers.Conv2D(32, 3, padding='same', activation='relu')(img_inputs)
    x = keras.layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)
    x = keras.layers.Conv2D(64, 3, strides=2, padding='same', activation='relu')(x)
    x = keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)
    shape_before_flatten = x.shape
    x = keras.layers.Flatten()(x)
    x = keras.layers.Dense(32, 'relu')(x)
    z_mean = keras.layers.Dense(latent_dim)(x)
    z_var = keras.layers.Dense(latent_dim)(x)
    z = Sampling()([z_mean, z_var])
    encoder = keras.Model(inputs=img_inputs, outputs=z, name='encoder')
    encoder.summary()

    # Define decoder model.
    latent_inputs = keras.Input((latent_dim,))
    x = keras.layers.Dense(np.prod(shape_before_flatten[1:]), activation='relu')(latent_inputs)
    x = keras.layers.Reshape(target_shape=shape_before_flatten[1:])(x)
    x = keras.layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)
    x = keras.layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)
    img_outputs = keras.layers.Conv2D(1, 3, padding='same', activation='sigmoid')(x)
    decoder = keras.Model(inputs=latent_inputs, outputs=img_outputs, name='decoder')
    decoder.summary()

    # Define VAE model.
    z = encoder(img_inputs)
    img_outputs = decoder(z)
    vae = keras.Model(inputs=img_inputs, outputs=img_outputs, name='vae')

    # add KL loss
    kl_loss = 0.5 * tf.reduce_mean(tf.square(z_mean) - 1 - z_var + tf.exp(z_var))

    vae.add_loss(kl_loss)
    return vae
